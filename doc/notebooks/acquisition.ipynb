{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "### Table of Contents\n",
    "- [Requirements](#requirements)\n",
    "- [Obtaining Historical Yield Data](#obtaining-historical-yield-data)\n",
    "- [Obtaining Historical Price Received Data](#obtaining-historical-price-received-data)\n",
    "- [Obtaining Historical Weather Data](#obtaining-historical-weather-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Yield Data\n",
    "#### (Grain & Silage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n",
      "Access key loaded.\n"
     ]
    }
   ],
   "source": [
    "# retrieving the access key for the USDA NASS API\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "with open('../../keys/api_key.txt', 'r') as file: # file path appears as `keys/api_key.txt` in `acquisition.py`\n",
    "    usda_nass_key = file.read()\n",
    "\n",
    "print('Access key loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment of variables for later use\n",
    "\n",
    "states = ['ILLINOIS', 'INDIANA', 'IOWA', 'MINNESOTA', 'MISSOURI', 'NEBRASKA']\n",
    "\n",
    "parameters = {\n",
    "    'key': usda_nass_key,\n",
    "    'source_desc': 'SURVEY',\n",
    "    'sector_desc': 'CROPS',\n",
    "    'group_desc': 'FIELD CROPS',\n",
    "    'commodity_desc': 'CORN',\n",
    "    'statisticcat_desc': 'YIELD',\n",
    "    'agg_level_desc': 'STATE',\n",
    "    'format': 'csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoding query parameters according to URL standards\n",
    "encoded_parameters = urllib.parse.urlencode(parameters)\n",
    "\n",
    "## establishing the URL base for the query\n",
    "base_url = 'https://quickstats.nass.usda.gov/api/api_GET/'\n",
    "\n",
    "## constructing the API query from the URL base and the URL encoded parameters\n",
    "query = base_url+'?'+encoded_parameters\n",
    "\n",
    "## fetching the query response\n",
    "response = requests.get(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as yield_raw.csv\n"
     ]
    }
   ],
   "source": [
    "## if the query was successful:\n",
    "if response.status_code == 200:\n",
    "\n",
    "    ### convert query response to text\n",
    "    data = StringIO(response.text)\n",
    "\n",
    "    ### convert response text to a pandas dataframe\n",
    "    yield_raw = pd.read_csv(data)\n",
    "\n",
    "    ### narrow the obtained dataset to only the necessary columns to reduce storage waste\n",
    "    yield_raw = yield_raw[['year', 'util_practice_desc', 'state_name', 'reference_period_desc', 'Value']]\n",
    "\n",
    "    ### we are only interested in the yearly recorded yield, not forecasts or monthly estimates\n",
    "    yield_raw = yield_raw[yield_raw['reference_period_desc'] == 'YEAR']\n",
    "\n",
    "    ### save the dataframe as a local CSV\n",
    "    yield_raw.to_csv('../../data/raw/yield_raw.csv', index=False) # file path appears as `data/raw/yield_raw.csv` in `acquisition.py`\n",
    "    print('Data saved as yield_raw.csv')\n",
    "\n",
    "## error handling\n",
    "else:\n",
    "    print(f'Request failed with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Price Received Data\n",
    "#### (By Month as well as Marketing Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since the historical price received data is too large to be fetched in one query, we fetch each state's data separately\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "for i, state in enumerate(states):\n",
    "\n",
    "    ## assignment of variables for later use\n",
    "    parameters = {\n",
    "        'key':usda_nass_key,\n",
    "        'source_desc':'SURVEY',\n",
    "        'sector_desc':'CROPS',\n",
    "        'group_desc':'FIELD CROPS',\n",
    "        'commodity_desc':'CORN',\n",
    "        'statisticcat_desc':'PRICE RECEIVED',\n",
    "        'agg_level_desc':'STATE',\n",
    "        'state_name':state,\n",
    "        'format':'csv'\n",
    "    }\n",
    "\n",
    "    ## encoding query parameters according to URL standards\n",
    "    encoded_parameters = urllib.parse.urlencode(parameters)\n",
    "\n",
    "    ## establishing the URL base for the query\n",
    "    base_url = 'https://quickstats.nass.usda.gov/api/api_GET/'\n",
    "\n",
    "    ## constructing the API query from the URL base and the URL encoded parameters\n",
    "    query = base_url+'?'+encoded_parameters\n",
    "\n",
    "    ## fetching the query response\n",
    "    response = requests.get(query)\n",
    "\n",
    "    ## if the query was successful:\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        ### for the first state, ILLINOIS, create the `price_received_raw` dataframe\n",
    "        if i == 0:\n",
    "            data = StringIO(response.text)\n",
    "            price_received_raw = pd.read_csv(data)\n",
    "            price_received_raw = price_received_raw[['year', 'state_name', 'reference_period_desc', 'Value']]\n",
    "\n",
    "        ### for every state thereafter, create a temporary dataframe with the 'next' state's data and merge it with the `price_received_raw` dataframe\n",
    "        else:\n",
    "            data = StringIO(response.text)\n",
    "            temp_df = pd.read_csv(data)\n",
    "            temp_df = temp_df[['year', 'state_name', 'reference_period_desc', 'Value']]\n",
    "            price_received_raw = pd.concat([price_received_raw, temp_df])\n",
    "\n",
    "    ## error handling\n",
    "    else:\n",
    "        print(f'Request failed for {state} with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as price_received_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# save the dataframe as a local CSV\n",
    "\n",
    "price_received_raw.to_csv('../../data/raw/price_received_raw.csv', index=False) # file path appears as `data/raw/price_received_raw.csv` in `acquisition.py`\n",
    "print('Data saved as price_received_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Weather Data\n",
    "#### (Average/Maximum/Minimum Temperature, Total Precipitation, & PDSI by Month from April through November)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assignment of variables for later use\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "state_numbers = [11, 12, 13, 21, 23, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenation_list = []\n",
    "## iterate through each state, variable, & month combination\n",
    "for state, state_number in zip(states, state_numbers):\n",
    "\n",
    "    merge_list = []\n",
    "    for variable in ['tavg', 'tmax', 'tmin', 'pcp', 'pdsi']:\n",
    "\n",
    "        ### skip the appropriate number of rows when reading the CSV\n",
    "        skiprows = 1 if variable == 'pdsi' else 2\n",
    "\n",
    "        link = f'https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series/{state_number}/{variable}/1/0/1895-2024/data.csv'\n",
    "        temp = pd.read_csv(link, skiprows=skiprows)\n",
    "\n",
    "        temp['State'] = state\n",
    "        temp['Year'] = temp['Date'].astype(str).str[:4].astype(int)\n",
    "        temp['Month'] = temp['Date'].astype(str).str[4:6].astype(int)\n",
    "        temp = temp\\\n",
    "            .rename(columns={'Value':variable})\\\n",
    "            .drop(columns='Date')\n",
    "\n",
    "        merge_list.append(temp)\n",
    "    \n",
    "    for i in range(1, len(merge_list)):\n",
    "        merge_list[0] = merge_list[0].merge(merge_list[i], on=['Year', 'Month', 'State'], how='outer')\n",
    "    concatenation_list.append(merge_list[0])\n",
    "\n",
    "weather_raw = pd.concat(concatenation_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as weather_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# save the dataframe as a local CSV\n",
    "\n",
    "weather_raw.to_csv('../../data/raw/weather_raw.csv', index=False) # file path appears as `data/raw/weather_raw.csv` in `acquisition.py`\n",
    "print('Data saved as weather_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corn-yield-independent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
