{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "### Table of Contents\n",
    "- [Requirements](#requirements)\n",
    "- [Obtaining Historical Yield Data](#obtaining-historical-yield-data)\n",
    "- [Obtaining Historical Price Received Data](#obtaining-historical-price-received-data)\n",
    "- [Obtaining Historical Weather Data](#obtaining-historical-weather-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Yield Data\n",
    "#### (Grain & Silage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieving the access key for the USDA NASS API\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "with open('../../keys/api_key.txt', 'r') as file: # file path appears as `keys/api_key.txt` in `acquisition.py`\n",
    "    usda_nass_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment of variables for later use\n",
    "\n",
    "states = ['ILLINOIS', 'INDIANA', 'IOWA', 'MINNESOTA', 'MISSOURI', 'NEBRASKA']\n",
    "\n",
    "parameters = {\n",
    "    'key': usda_nass_key,\n",
    "    'source_desc': 'SURVEY',\n",
    "    'sector_desc': 'CROPS',\n",
    "    'group_desc': 'FIELD CROPS',\n",
    "    'commodity_desc': 'CORN',\n",
    "    'statisticcat_desc': 'YIELD',\n",
    "    'agg_level_desc': 'STATE',\n",
    "    'format': 'csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoding query parameters according to URL standards\n",
    "encoded_parameters = urllib.parse.urlencode(parameters)\n",
    "\n",
    "## establishing the URL base for the query\n",
    "base_url = 'https://quickstats.nass.usda.gov/api/api_GET/'\n",
    "\n",
    "## constructing the API query from the URL base and the URL encoded parameters\n",
    "query = base_url+'?'+encoded_parameters\n",
    "\n",
    "## fetching the query response\n",
    "response = requests.get(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as yield_raw.csv\n"
     ]
    }
   ],
   "source": [
    "## if the query was successful:\n",
    "if response.status_code == 200:\n",
    "\n",
    "    ### convert query response to text\n",
    "    data = StringIO(response.text)\n",
    "\n",
    "    ### convert response text to a pandas dataframe\n",
    "    yield_raw = pd.read_csv(data)\n",
    "\n",
    "    ### narrow the obtained dataset to only the necessary columns to reduce storage waste\n",
    "    yield_raw = yield_raw[['year', 'util_practice_desc', 'state_name', 'reference_period_desc', 'Value']]\n",
    "\n",
    "    ### we are only interested in the yearly recorded yield, not forecasts or monthly estimates\n",
    "    yield_raw = yield_raw[yield_raw['reference_period_desc'] == 'YEAR']\n",
    "\n",
    "    ### save the dataframe as a local CSV\n",
    "    yield_raw.to_csv('../../data/raw/yield_raw.csv', index=False) # file path appears as `data/raw/yield_raw.csv` in `acquisition.py`\n",
    "    print('Data saved as yield_raw.csv')\n",
    "\n",
    "## error handling\n",
    "else:\n",
    "    print(f'Request failed with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Price Received Data\n",
    "#### (By Month as well as Marketing Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since the historical price received data is too large to be fetched in one query, we fetch each state's data separately\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "for i, state in enumerate(states):\n",
    "\n",
    "    ## assignment of variables for later use\n",
    "    parameters = {\n",
    "        'key': usda_nass_key,\n",
    "        'source_desc': 'SURVEY',\n",
    "        'sector_desc': 'CROPS',\n",
    "        'group_desc': 'FIELD CROPS',\n",
    "        'commodity_desc': 'CORN',\n",
    "        'statisticcat_desc': 'PRICE RECEIVED',\n",
    "        'agg_level_desc': 'STATE',\n",
    "        'state_name':state,\n",
    "        'format': 'csv'\n",
    "    }\n",
    "\n",
    "    ## encoding query parameters according to URL standards\n",
    "    encoded_parameters = urllib.parse.urlencode(parameters)\n",
    "\n",
    "    ## establishing the URL base for the query\n",
    "    base_url = 'https://quickstats.nass.usda.gov/api/api_GET/'\n",
    "\n",
    "    ## constructing the API query from the URL base and the URL encoded parameters\n",
    "    query = base_url+'?'+encoded_parameters\n",
    "\n",
    "    ## fetching the query response\n",
    "    response = requests.get(query)\n",
    "\n",
    "    ## if the query was successful:\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        ### for the first state, ILLINOIS, create the `price_received_raw` dataframe\n",
    "        if i == 0:\n",
    "            data = StringIO(response.text)\n",
    "            price_received_raw = pd.read_csv(data)\n",
    "            price_received_raw = price_received_raw[['year', 'state_name', 'reference_period_desc', 'Value']]\n",
    "\n",
    "        ### for every state thereafter, create a temporary dataframe with the 'next' state's data and merge it with the `price_received_raw` dataframe\n",
    "        else:\n",
    "            data = StringIO(response.text)\n",
    "            temp_df = pd.read_csv(data)\n",
    "            temp_df = temp_df[['year', 'state_name', 'reference_period_desc', 'Value']]\n",
    "            price_received_raw = pd.concat([price_received_raw, temp_df])\n",
    "\n",
    "    ## error handling\n",
    "    else:\n",
    "        print(f'Request failed for {state} with status code {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as price_received_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# save the dataframe as a local CSV\n",
    "\n",
    "price_received_raw.to_csv('../../data/raw/price_received_raw.csv', index=False) # file path appears as `data/raw/price_received_raw.csv` in `acquisition.py`\n",
    "print('Data saved as price_received_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Historical Weather Data\n",
    "#### (Average/Maximum/Minimum Temperature, Total Precipitation, & PDSI by Month from April through November)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assignment of variables for later use\n",
    "\n",
    "print('\\nLoading...\\n')\n",
    "\n",
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "state_numbers = [11, 12, 13, 21, 23, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an empty dataframe template of years and states\n",
    "years = list(range(1895, 2025))*6\n",
    "years.sort()\n",
    "list_temp = list(range(0, 6))*130\n",
    "df_empty = pd.DataFrame({'year':years, 'state':list_temp})\n",
    "df_empty['state'] = df_empty['state'].replace({i: states[i] for i in range(len(states))})\n",
    "\n",
    "## create a copy of the empty dataframe template\n",
    "weather_raw = df_empty.copy()\n",
    "\n",
    "## iterate through each state, variable, & month combination\n",
    "for s, state_number in enumerate(state_numbers):\n",
    "    for variable in ['tavg', 'tmax', 'tmin', 'pcp', 'pdsi']:\n",
    "        for m, month in enumerate(months):\n",
    "\n",
    "            ### find the state\n",
    "            state = states[s]\n",
    "\n",
    "            ### skip the appropriate number of rows when reading the CSV\n",
    "            skiprows = 3 if variable == 'pdsi' else 4\n",
    "\n",
    "            ### construct the appropriate CSV link\n",
    "            link = f'https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series/{state_number}/{variable}/12/{m+1}/1895-2024.csv?base_prd=true&begbaseyear=1895&endbaseyear=2000'\n",
    "\n",
    "            ### create the temporary dataframe\n",
    "            temp = pd.read_csv(link, skiprows=skiprows)\n",
    "\n",
    "            ### reformat the `Date` column to be YYYY\n",
    "            temp['Date'] = temp['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "\n",
    "            ### rename `Date` to `year`\n",
    "            temp.rename(columns={'Date':'year'}, inplace=True)\n",
    "\n",
    "            ### rename `Value` columns to `{month}-{var}`\n",
    "            temp.rename(columns={'Value':f'{month}_{variable}'}, inplace=True)\n",
    "\n",
    "            ### map the `temp` values to `weather_raw`\n",
    "            weather_raw.loc[weather_raw['state'] == state, f'{month}_{variable}'] = weather_raw.loc[weather_raw['state'] == state, 'year'].map(temp.set_index('year')[f'{month}_{variable}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as weather_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# save the dataframe as a local CSV\n",
    "\n",
    "weather_raw.to_csv('../../data/raw/weather_raw.csv', index=False) # file path appears as `data/raw/weather_raw.csv` in `acquisition.py`\n",
    "print('Data saved as weather_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
